\chapter{Fazit und Ausblick}
In dieser Thesis wurden verschiedene Modelle des maschinellen Lernens entwickelt
und evaluiert. Vor allem wurden sogenannte Generative-Adversarial-Networks
(GANs) erforscht und neue Methoden zum Erzeugen von künstlichen Bewegungen
gesucht, um einen kompletten Datensatz mithilfe eines solchen Modells zu
erzeugen. Als Ergebnis wurde zuerst ViGAN präsentiert. Ziel von ViGAN ist es,
aus einem bestehenden Video-Datensatz neue bisher unbekannte Proben zu erzeugen.
Dies gelang auch bis zu einem gewissen Grad. Es wurden zwar neue Videos vom
Netzwerk erzeugt, jedoch konnte nicht sichergestellt werden, ob sich eine Person
tatsächlich bewegt oder still steht.  So sind Personen oft regungslose starre
Körper, während sich z.B. ganze Räume über die Zeit verändern. Als Alternative
dazu wurde KpGAN entworfen, welches direkt verschiedenste Bewegungsanimationen
erzeugen kann. Diese Bewegungsanimationen bestehen dabei aus menschlichen
Schlüsselpunkten und werden als Bilder kodiert.  Experimente haben gezeigt, dass
Datensätze, die komplett mithilfe von KpGAN erzeugt wurden, mindestens genau so
gut für das Training anderer Modelle geeignet sind, wie entsprechende reale
Datensätze.  Dies bringt einen großen Vorteil mit sich, denn der eigentliche
Datensatz kann ohne großen Aufwand beliebig erweitert werden, während beim
realen Datensatz ein signifikanter Zeitaufwand entstehen würde.

Im Anschluss wurden mithilfe von KpGAN weitere neuronale Netzwerke trainiert,
die Bewegungen aus Schlüsselpunktsequenzen erkennen sollen.  Die Herausforderung
ist dabei die Echtzeiterkennung auf mobilen Geräten. Die verwendeten Metriken
waren Genauigkeit und Performance. Aus den Experimenten resultierte schließlich
das MotionNet, welches eine sehr gute Erkennungsrate und Ausführungsgeschwindigkeit
besitzt.  Mithilfe des trainierten MotionNets und eines externen Modells von
Google (MoveNet-Lightning) wurde anschließend eine mobile App entwickelt, welche
die Anwendbarkeit und Performance auf mobilen Geräten messen soll. Auf modernen
Smartphones wurde eine Aus\-führ\-ungs\-ge\-schwindig\-keit von bis zu 14 FPS
gemessen. Auch wurde durch Praxistests bewiesen, dass eine Bewegungserkennung
auf modernen und älteren mobilen Plattformen in Echtzeit ausführbar ist und
tatsächlich Bewegungen erkennt. Damit wurde die Forschungsfrage, ob eine
Bewegungserkennung auf mobilen Geräten in Echtzeit ausgeführt werden kann,
beantwortet und eine Beispiel-App präsentiert.

Weiterführende Arbeiten können sich in Zukunft mit dem Verbessern des ViGAN
be\-schäf\-tigen, um das Problem mit den sich nicht bewegenden Personen in
Videos zu lösen. Zudem kann das MotionNet um weitere Bewegungen erweitert
werden. Die hier vorgestellte Lösung zum Erkennen von Bewegungen findet
lediglich im zweidimensionalen Raum statt. Interessant wäre es zu wissen, ob
eine dreidimensionale Repräsentation der menschlichen Schlüsselpunkte zu anderen
Ergebnissen führen würde. Dies könnte in Zukunft ebenfalls weiter
untersucht werden.
